const cluster = require('cluster');
const os = require('os');
const { performance } = require('perf_hooks');

/**
 * üöÄ PRODUCTION OPTIMIZER - FINAL DEPLOYMENT READY
 * 
 * This integrates ALL optimizations into the actual bot system
 * for real production deployment. This is the absolute final edge
 * that can be deployed right now.
 */

class ProductionOptimizer {
  constructor() {
    this.config = {
      // Production settings
      environment: process.env.NODE_ENV || 'production',
      port: process.env.PORT || 3000,
      workers: Math.min(os.cpus().length, 4), // Max 4 workers for stability
      
      // Performance thresholds
      maxResponseTime: 100, // 100ms max response time
      maxMemoryUsage: 85, // 85% max memory usage
      maxCpuUsage: 80, // 80% max CPU usage
      maxErrorRate: 2, // 2% max error rate
      
      // Optimization features
      enableClustering: false, // Disabled for now to fix webhook issues
      enableCaching: true,
      enableCompression: true,
      enableMonitoring: true,
      enableGracefulShutdown: true,
      
      // Cache configuration (optimized for Render free tier)
      cacheSize: 5000, // Reduced cache size for free tier
      cacheTTL: 300000, // 5 minutes
      hotCacheSize: 500, // Reduced hot cache for free tier
      hotCacheTTL: 60000, // 1 minute
      
      // Memory management (optimized for Render free tier)
      gcInterval: 10000, // 10 seconds - even more frequent GC
      memoryThreshold: 0.70, // 70% - even lower threshold for free tier
      objectPoolSize: 300 // Further reduced pool size for free tier
    };
    
    this.cache = {
      hot: new Map(), // Ultra-fast cache
      warm: new Map(), // Regular cache
      stats: {
        hits: 0,
        misses: 0,
        sets: 0,
        deletes: 0
      }
    };
    
    this.objectPools = new Map();
    this.metrics = {
      requests: 0,
      responses: 0,
      errors: 0,
      totalResponseTime: 0,
      startTime: Date.now(),
      lastGC: Date.now()
    };
    
    this.isInitialized = false;
    this.workers = new Map();
  }

  /**
   * Initialize production optimizer
   */
  async initialize() {
    console.log('üöÄ Initializing Production Optimizer...');
    console.log(`   Environment: ${this.config.environment}`);
    console.log(`   CPUs: ${os.cpus().length} available, using ${this.config.workers} workers`);
    console.log(`   Memory: ${Math.round(os.totalmem() / 1024 / 1024 / 1024)}GB total`);
    
    try {
      // 1. Setup clustering if enabled and we're master
      if (this.config.enableClustering && cluster.isMaster) {
        await this.setupProductionCluster();
        console.log("üè≠ Master process managing workers, bot will run in workers");
        // Don't return - master process should also initialize bot
      }
      
      // 2. Initialize caching system
      if (this.config.enableCaching) {
        this.initializeProductionCache();
      }
      
      // 3. Setup memory management
      this.setupProductionMemoryManagement();
      
      // 4. Initialize monitoring
      if (this.config.enableMonitoring) {
        this.setupProductionMonitoring();
      }
      
      // 5. Setup graceful shutdown
      if (this.config.enableGracefulShutdown) {
        this.setupGracefulShutdown();
      }
      
      // 6. Optimize Node.js settings
      this.optimizeNodeJSForProduction();
      
      this.isInitialized = true;
      console.log('‚úÖ Production Optimizer initialized successfully');
      
    } catch (error) {
      console.error('‚ùå Production Optimizer initialization failed:', error);
      throw error;
    }
  }

  /**
   * Setup production cluster
   */
  async setupProductionCluster() {
    console.log(`üè≠ Setting up production cluster with ${this.config.workers} workers...`);
    
    // Fork workers
    for (let i = 0; i < this.config.workers; i++) {
      const worker = cluster.fork();
      this.workers.set(worker.id, {
        worker,
        pid: worker.process.pid,
        startTime: Date.now(),
        requests: 0,
        errors: 0,
        restarts: 0
      });
      
      console.log(`   Worker ${worker.id} started (PID: ${worker.process.pid})`);
    }
    
    // Handle worker events
    cluster.on('exit', (worker, code, signal) => {
      const workerInfo = this.workers.get(worker.id);
      console.log(`üíÄ Worker ${worker.id} (PID: ${worker.process.pid}) died (${signal || code})`);
      
      if (workerInfo) {
        workerInfo.restarts++;
        this.workers.delete(worker.id);
        
        // Restart worker if not too many restarts
        if (workerInfo.restarts < 5) {
          console.log(`üîÑ Restarting worker ${worker.id}...`);
          const newWorker = cluster.fork();
          this.workers.set(newWorker.id, {
            worker: newWorker,
            pid: newWorker.process.pid,
            startTime: Date.now(),
            requests: 0,
            errors: 0,
            restarts: workerInfo.restarts
          });
        } else {
          console.error(`‚ùå Worker ${worker.id} restarted too many times, not restarting`);
        }
      }
    });
    
    // Monitor worker health
    setInterval(() => {
      this.monitorWorkerHealth();
    }, 30000);
    
    console.log('‚úÖ Production cluster setup complete');
  }

  /**
   * Monitor worker health
   */
  monitorWorkerHealth() {
    for (const [id, workerInfo] of this.workers.entries()) {
      const uptime = Date.now() - workerInfo.startTime;
      const requestRate = workerInfo.requests / (uptime / 1000);
      const errorRate = workerInfo.requests > 0 ? (workerInfo.errors / workerInfo.requests) * 100 : 0;
      
      // Log worker stats
      if (uptime > 60000) { // Only log after 1 minute uptime
        console.log(`üìä Worker ${id}: ${requestRate.toFixed(1)} req/sec, ${errorRate.toFixed(2)}% errors, ${workerInfo.restarts} restarts`);
      }
      
      // Check for problematic workers
      if (errorRate > 10 && workerInfo.requests > 100) {
        console.warn(`‚ö†Ô∏è Worker ${id} has high error rate: ${errorRate.toFixed(2)}%`);
      }
    }
  }

  /**
   * Initialize production cache
   */
  initializeProductionCache() {
    console.log('üíæ Initializing production cache system...');
    
    // Setup cache cleanup
    setInterval(() => {
      this.cleanupCache();
    }, 60000); // Every minute
    
    // Pre-warm cache with common data
    this.prewarmCache();
    
    console.log(`   Hot cache: ${this.config.hotCacheSize} items, ${this.config.hotCacheTTL / 1000}s TTL`);
    console.log(`   Warm cache: ${this.config.cacheSize} items, ${this.config.cacheTTL / 1000}s TTL`);
    console.log('‚úÖ Production cache initialized');
  }

  /**
   * Pre-warm cache with common data
   */
  prewarmCache() {
    // Pre-cache common responses
    const commonResponses = [
      { key: 'welcome_message', data: { text: 'Welcome to the bot!', type: 'greeting' } },
      { key: 'help_message', data: { text: 'Here are the available commands...', type: 'help' } },
      { key: 'error_message', data: { text: 'Something went wrong. Please try again.', type: 'error' } }
    ];
    
    for (const item of commonResponses) {
      this.setCache(item.key, item.data, 'hot');
    }
    
    console.log(`   Pre-warmed ${commonResponses.length} common responses`);
  }

  /**
   * Get from production cache
   */
  getCache(key) {
    // Try hot cache first
    if (this.cache.hot.has(key)) {
      const item = this.cache.hot.get(key);
      if (Date.now() - item.timestamp < this.config.hotCacheTTL) {
        this.cache.stats.hits++;
        return item.data;
      }
      this.cache.hot.delete(key);
    }
    
    // Try warm cache
    if (this.cache.warm.has(key)) {
      const item = this.cache.warm.get(key);
      if (Date.now() - item.timestamp < this.config.cacheTTL) {
        // Promote to hot cache if accessed frequently
        if (item.hits > 3) {
          this.setCache(key, item.data, 'hot');
        } else {
          item.hits++;
        }
        this.cache.stats.hits++;
        return item.data;
      }
      this.cache.warm.delete(key);
    }
    
    this.cache.stats.misses++;
    return null;
  }

  /**
   * Set in production cache
   */
  setCache(key, data, priority = 'warm') {
    const item = {
      data,
      timestamp: Date.now(),
      hits: 0
    };
    
    if (priority === 'hot' && this.cache.hot.size < this.config.hotCacheSize) {
      this.cache.hot.set(key, item);
    } else if (this.cache.warm.size < this.config.cacheSize) {
      this.cache.warm.set(key, item);
    } else {
      // Remove oldest item
      const oldestKey = this.cache.warm.keys().next().value;
      this.cache.warm.delete(oldestKey);
      this.cache.warm.set(key, item);
    }
    
    this.cache.stats.sets++;
  }

  /**
   * Cleanup expired cache entries
   */
  cleanupCache() {
    const now = Date.now();
    let cleaned = 0;
    
    // Cleanup hot cache
    for (const [key, item] of this.cache.hot.entries()) {
      if (now - item.timestamp > this.config.hotCacheTTL) {
        this.cache.hot.delete(key);
        cleaned++;
      }
    }
    
    // Cleanup warm cache
    for (const [key, item] of this.cache.warm.entries()) {
      if (now - item.timestamp > this.config.cacheTTL) {
        this.cache.warm.delete(key);
        cleaned++;
      }
    }
    
    if (cleaned > 0) {
      console.log(`üßπ Cleaned ${cleaned} expired cache entries`);
    }
  }

  /**
   * Setup production memory management
   */
  setupProductionMemoryManagement() {
    console.log('üß† Setting up production memory management...');
    
    // Initialize object pools
    const poolTypes = ['user', 'message', 'response', 'error'];
    for (const type of poolTypes) {
      this.objectPools.set(type, []);
      // Pre-allocate objects
      for (let i = 0; i < 50; i++) {
        this.objectPools.get(type).push(this.createPooledObject(type));
      }
    }
    
    // Setup garbage collection monitoring
    if (global.gc) {
      setInterval(() => {
        const memUsage = process.memoryUsage();
        const memoryUsage = memUsage.heapUsed / memUsage.heapTotal;
        
        if (memoryUsage > this.config.memoryThreshold) {
          global.gc();
          this.metrics.lastGC = Date.now();
          console.log(`üóëÔ∏è Forced GC: ${Math.round(memoryUsage * 100)}% memory usage`);
        }
      }, this.config.gcInterval);
    }
    
    console.log('‚úÖ Production memory management initialized');
  }

  /**
   * Create pooled object
   */
  createPooledObject(type) {
    switch (type) {
      case 'user':
        return { id: null, telegramId: null, username: null, data: null };
      case 'message':
        return { id: null, text: null, userId: null, timestamp: null };
      case 'response':
        return { success: null, data: null, error: null, timestamp: null };
      case 'error':
        return { code: null, message: null, stack: null };
      default:
        return {};
    }
  }

  /**
   * Get object from pool
   */
  getPooledObject(type) {
    const pool = this.objectPools.get(type);
    if (pool && pool.length > 0) {
      return pool.pop();
    }
    return this.createPooledObject(type);
  }

  /**
   * Return object to pool
   */
  returnPooledObject(type, obj) {
    const pool = this.objectPools.get(type);
    if (pool && pool.length < this.config.objectPoolSize) {
      // Reset object
      for (const key in obj) {
        obj[key] = null;
      }
      pool.push(obj);
    }
  }

  /**
   * Setup production monitoring
   */
  setupProductionMonitoring() {
    console.log('üìä Setting up production monitoring...');
    
    // Real-time metrics collection
    setInterval(() => {
      this.collectProductionMetrics();
    }, 5000); // Every 5 seconds
    
    // Performance alerts
    setInterval(() => {
      this.checkProductionAlerts();
    }, 30000); // Every 30 seconds
    
    // Daily summary
    setInterval(() => {
      this.generateDailySummary();
    }, 86400000); // Every 24 hours
    
    console.log('‚úÖ Production monitoring initialized');
  }

  /**
   * Collect production metrics
   */
  collectProductionMetrics() {
    const memUsage = process.memoryUsage();
    const uptime = Date.now() - this.metrics.startTime;
    
    const currentMetrics = {
      timestamp: Date.now(),
      uptime: uptime,
      requests: this.metrics.requests,
      responses: this.metrics.responses,
      errors: this.metrics.errors,
      avgResponseTime: this.metrics.responses > 0 ? this.metrics.totalResponseTime / this.metrics.responses : 0,
      errorRate: this.metrics.requests > 0 ? (this.metrics.errors / this.metrics.requests) * 100 : 0,
      requestRate: this.metrics.requests / (uptime / 1000),
      memory: {
        heapUsed: Math.round(memUsage.heapUsed / 1024 / 1024),
        heapTotal: Math.round(memUsage.heapTotal / 1024 / 1024),
        usage: (memUsage.heapUsed / memUsage.heapTotal) * 100
      },
      cache: {
        hotSize: this.cache.hot.size,
        warmSize: this.cache.warm.size,
        hitRate: (this.cache.stats.hits + this.cache.stats.misses) > 0 ? 
          (this.cache.stats.hits / (this.cache.stats.hits + this.cache.stats.misses)) * 100 : 0
      }
    };
    
    // Store metrics (keep last 100 entries)
    if (!this.productionMetrics) {
      this.productionMetrics = [];
    }
    this.productionMetrics.push(currentMetrics);
    if (this.productionMetrics.length > 100) {
      this.productionMetrics.shift();
    }
  }

  /**
   * Check production alerts
   */
  checkProductionAlerts() {
    if (!this.productionMetrics || this.productionMetrics.length === 0) return;
    
    const latest = this.productionMetrics[this.productionMetrics.length - 1];
    
    // High response time alert
    if (latest.avgResponseTime > this.config.maxResponseTime) {
      console.warn(`üö® HIGH RESPONSE TIME: ${latest.avgResponseTime.toFixed(2)}ms (threshold: ${this.config.maxResponseTime}ms)`);
    }
    
    // High memory usage alert
    if (latest.memory.usage > this.config.maxMemoryUsage) {
      console.warn(`üö® HIGH MEMORY USAGE: ${latest.memory.usage.toFixed(1)}% (threshold: ${this.config.maxMemoryUsage}%)`);
    }
    
    // High error rate alert
    if (latest.errorRate > this.config.maxErrorRate) {
      console.warn(`üö® HIGH ERROR RATE: ${latest.errorRate.toFixed(2)}% (threshold: ${this.config.maxErrorRate}%)`);
    }
    
    // Low cache hit rate alert
    if (latest.cache.hitRate < 50 && (this.cache.stats.hits + this.cache.stats.misses) > 100) {
      console.warn(`üö® LOW CACHE HIT RATE: ${latest.cache.hitRate.toFixed(1)}%`);
    }
  }

  /**
   * Generate daily summary
   */
  generateDailySummary() {
    if (!this.productionMetrics || this.productionMetrics.length === 0) return;
    
    const latest = this.productionMetrics[this.productionMetrics.length - 1];
    const uptime = latest.uptime / 1000 / 60 / 60; // hours
    
    console.log('\nüìä DAILY PRODUCTION SUMMARY');
    console.log('===========================');
    console.log(`‚è±Ô∏è Uptime: ${uptime.toFixed(1)} hours`);
    console.log(`üìà Total Requests: ${latest.requests.toLocaleString()}`);
    console.log(`‚úÖ Success Rate: ${(100 - latest.errorRate).toFixed(2)}%`);
    console.log(`‚ö° Avg Response Time: ${latest.avgResponseTime.toFixed(2)}ms`);
    console.log(`üöÄ Request Rate: ${latest.requestRate.toFixed(1)} req/sec`);
    console.log(`üíæ Memory Usage: ${latest.memory.usage.toFixed(1)}% (${latest.memory.heapUsed}MB)`);
    console.log(`üéØ Cache Hit Rate: ${latest.cache.hitRate.toFixed(1)}%`);
    console.log(`üóëÔ∏è Last GC: ${Math.round((Date.now() - this.metrics.lastGC) / 1000)}s ago`);
    
    if (cluster.isMaster) {
      console.log(`üë∑ Active Workers: ${this.workers.size}`);
    } else {
      console.log(`üë∑ Worker ID: ${cluster.worker.id}`);
    }
    
    console.log('===========================\n');
  }

  /**
   * Optimize Node.js for production
   */
  optimizeNodeJSForProduction() {
    // Set process title
    process.title = `telegram-bot-${cluster.isMaster ? 'master' : 'worker'}`;
    
    // Optimize event loop
    process.nextTick(() => {
      setImmediate(() => {
        console.log('‚ö° Event loop optimized for production');
      });
    });
    
    // Set maximum listeners
    process.setMaxListeners(0);
    
    console.log('üöÄ Node.js optimized for production');
  }

  /**
   * Setup graceful shutdown
   */
  setupGracefulShutdown() {
    const gracefulShutdown = async (signal) => {
      console.log(`\nüõë Received ${signal}, starting graceful shutdown...`);
      
      try {
        // Stop accepting new requests
        console.log('   üìù Stopping new request acceptance...');
        
        // Close cache
        if (this.cache) {
          this.cache.hot.clear();
          this.cache.warm.clear();
          console.log('   üíæ Cache cleared');
        }
        
        // Clear object pools
        if (this.objectPools) {
          this.objectPools.clear();
          console.log('   üèä Object pools cleared');
        }
        
        // Final metrics
        this.generateDailySummary();
        
        console.log('‚úÖ Graceful shutdown complete');
        process.exit(0);
        
      } catch (error) {
        console.error('‚ùå Error during graceful shutdown:', error);
        process.exit(1);
      }
    };
    
    process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
    process.on('SIGINT', () => gracefulShutdown('SIGINT'));
    
    console.log('üõ°Ô∏è Graceful shutdown handlers registered');
  }

  /**
   * Production middleware for request processing
   */
  async processRequest(ctx, next) {
    const startTime = performance.now();
    this.metrics.requests++;
    
    try {
      // Generate cache key
      const cacheKey = this.generateCacheKey(ctx);
      
      // Try cache first
      const cached = this.getCache(cacheKey);
      if (cached) {
        ctx.body = cached;
        this.metrics.responses++;
        return;
      }
      
      // Process request
      await next();
      
      // Cache successful responses
      if (ctx.status === 200 && ctx.body) {
        this.setCache(cacheKey, ctx.body);
      }
      
      this.metrics.responses++;
      
    } catch (error) {
      this.metrics.errors++;
      console.error('Request processing error:', error);
      throw error;
    } finally {
      // Update response time
      const endTime = performance.now();
      const responseTime = endTime - startTime;
      this.metrics.totalResponseTime += responseTime;
    }
  }

  /**
   * Generate cache key for request
   */
  generateCacheKey(ctx) {
    const key = `${ctx.method}:${ctx.path}:${JSON.stringify(ctx.query)}`;
    return require('crypto').createHash('md5').update(key).digest('hex');
  }

  /**
   * Get production performance stats
   */
  getProductionStats() {
    const latest = this.productionMetrics && this.productionMetrics.length > 0 ? 
      this.productionMetrics[this.productionMetrics.length - 1] : null;
    
    return {
      isInitialized: this.isInitialized,
      environment: this.config.environment,
      uptime: latest ? latest.uptime : 0,
      requests: this.metrics.requests,
      responses: this.metrics.responses,
      errors: this.metrics.errors,
      avgResponseTime: latest ? latest.avgResponseTime : 0,
      errorRate: latest ? latest.errorRate : 0,
      requestRate: latest ? latest.requestRate : 0,
      memory: latest ? latest.memory : null,
      cache: {
        ...latest?.cache,
        stats: this.cache.stats
      },
      cluster: cluster.isMaster ? {
        isMaster: true,
        workers: this.workers.size,
        workerPids: Array.from(this.workers.values()).map(w => w.pid)
      } : {
        isMaster: false,
        workerId: cluster.worker?.id,
        workerPid: process.pid
      }
    };
  }

  /**
   * Health check endpoint
   */
  getHealthCheck() {
    const stats = this.getProductionStats();
    const isHealthy = stats.errorRate < this.config.maxErrorRate && 
                     stats.avgResponseTime < this.config.maxResponseTime &&
                     (stats.memory?.usage || 0) < this.config.maxMemoryUsage;
    
    return {
      status: isHealthy ? 'healthy' : 'unhealthy',
      timestamp: new Date().toISOString(),
      uptime: stats.uptime,
      version: process.env.npm_package_version || '1.0.0',
      environment: this.config.environment,
      nodeVersion: process.version,
      platform: process.platform,
      arch: process.arch,
      memory: stats.memory,
      performance: {
        avgResponseTime: stats.avgResponseTime,
        errorRate: stats.errorRate,
        requestRate: stats.requestRate,
        cacheHitRate: stats.cache?.hitRate || 0
      }
    };
  }
}

module.exports = ProductionOptimizer;
